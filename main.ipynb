{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (3.8.4)\n",
      "Requirement already satisfied: seaborn in /opt/anaconda3/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.12/site-packages (1.97.1)\n",
      "Requirement already satisfied: fpdf2 in /opt/anaconda3/lib/python3.12/site-packages (2.8.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: defusedxml in /opt/anaconda3/lib/python3.12/site-packages (from fpdf2) (0.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas matplotlib seaborn openai fpdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import openai\n",
    "import io\n",
    "import base64\n",
    "from typing import Dict, List, Any\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set page config\n",
    "st.set_page_config(\n",
    "    page_title=\"Auto Report Generator\",\n",
    "    page_icon=\"📊\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(self, uploaded_file):\n",
    "        \"\"\"Load data from uploaded file\"\"\"\n",
    "        try:\n",
    "            if uploaded_file.name.endswith('.csv'):\n",
    "                self.df = pd.read_csv(uploaded_file)\n",
    "            elif uploaded_file.name.endswith(('.xlsx', '.xls')):\n",
    "                self.df = pd.read_excel(uploaded_file)\n",
    "            elif uploaded_file.name.endswith('.json'):\n",
    "                self.df = pd.read_json(uploaded_file)\n",
    "            else:\n",
    "                st.error(\"Unsupported file format. Please upload CSV, Excel, or JSON files.\")\n",
    "                return False\n",
    "            \n",
    "            st.success(f\"Data loaded successfully! Shape: {self.df.shape}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error loading data: {str(e)}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Generate comprehensive data summary\"\"\"\n",
    "        if self.df is None:\n",
    "            return {}\n",
    "        \n",
    "        summary = {\n",
    "            \"shape\": self.df.shape,\n",
    "            \"columns\": list(self.df.columns),\n",
    "            \"dtypes\": self.df.dtypes.to_dict(),\n",
    "            \"missing_values\": self.df.isnull().sum().to_dict(),\n",
    "            \"numeric_columns\": list(self.df.select_dtypes(include=[np.number]).columns),\n",
    "            \"categorical_columns\": list(self.df.select_dtypes(include=['object']).columns),\n",
    "            \"memory_usage\": self.df.memory_usage(deep=True).sum(),\n",
    "            \"duplicate_rows\": self.df.duplicated().sum()\n",
    "        }\n",
    "        \n",
    "        # Add basic statistics for numeric columns\n",
    "        if summary[\"numeric_columns\"]:\n",
    "            summary[\"numeric_stats\"] = self.df[summary[\"numeric_columns\"]].describe().to_dict()\n",
    "        \n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_eda(self, user_prompt: str = None) -> Dict[str, Any]:\n",
    "        \"\"\"Perform comprehensive EDA based on user prompt or default analysis\"\"\"\n",
    "        if self.df is None:\n",
    "            return {}\n",
    "        \n",
    "        eda_results = {}\n",
    "        \n",
    "        # Basic data info\n",
    "        eda_results[\"data_summary\"] = self.get_data_summary()\n",
    "        \n",
    "        # Correlation analysis for numeric columns\n",
    "        numeric_cols = self.df.select_dtypes(include=[np.number]).columns\n",
    "        if len(numeric_cols) > 1:\n",
    "            eda_results[\"correlation_matrix\"] = self.df[numeric_cols].corr().to_dict()\n",
    "        \n",
    "        # Distribution analysis\n",
    "        eda_results[\"distributions\"] = {}\n",
    "        for col in numeric_cols:\n",
    "            eda_results[\"distributions\"][col] = {\n",
    "                \"mean\": float(self.df[col].mean()),\n",
    "                \"median\": float(self.df[col].median()),\n",
    "                \"std\": float(self.df[col].std()),\n",
    "                \"skewness\": float(self.df[col].skew()),\n",
    "                \"kurtosis\": float(self.df[col].kurtosis())\n",
    "            }\n",
    "        \n",
    "        # Categorical analysis\n",
    "        categorical_cols = self.df.select_dtypes(include=['object']).columns\n",
    "        eda_results[\"categorical_analysis\"] = {}\n",
    "        for col in categorical_cols:\n",
    "            value_counts = self.df[col].value_counts().head(10)\n",
    "            eda_results[\"categorical_analysis\"][col] = {\n",
    "                \"unique_values\": int(self.df[col].nunique()),\n",
    "                \"top_values\": value_counts.to_dict(),\n",
    "                \"most_frequent\": str(value_counts.index[0]) if len(value_counts) > 0 else None\n",
    "            }\n",
    "        \n",
    "        self.analysis_results = eda_results\n",
    "        return eda_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_visualizations(self):\n",
    "        \"\"\"Generate various visualizations based on the data\"\"\"\n",
    "        if self.df is None:\n",
    "            return []\n",
    "        \n",
    "        figures = []\n",
    "        numeric_cols = self.df.select_dtypes(include=[np.number]).columns\n",
    "        categorical_cols = self.df.select_dtypes(include=['object']).columns\n",
    "        \n",
    "        # 1. Correlation heatmap\n",
    "        if len(numeric_cols) > 1:\n",
    "            fig_corr = px.imshow(\n",
    "                self.df[numeric_cols].corr(),\n",
    "                text_auto=True,\n",
    "                aspect=\"auto\",\n",
    "                title=\"Correlation Matrix\",\n",
    "                color_continuous_scale=\"RdBu\"\n",
    "            )\n",
    "            figures.append((\"Correlation Matrix\", fig_corr))\n",
    "        \n",
    "        # 2. Distribution plots for numeric columns\n",
    "        if len(numeric_cols) > 0:\n",
    "            for col in numeric_cols[:4]:  # Limit to first 4 columns\n",
    "                fig_dist = px.histogram(\n",
    "                    self.df, \n",
    "                    x=col, \n",
    "                    title=f\"Distribution of {col}\",\n",
    "                    marginal=\"box\"\n",
    "                )\n",
    "                figures.append((f\"Distribution of {col}\", fig_dist))\n",
    "        \n",
    "        # 3. Box plots for numeric columns\n",
    "        if len(numeric_cols) > 1:\n",
    "            fig_box = go.Figure()\n",
    "            for col in numeric_cols[:5]:  # Limit to first 5 columns\n",
    "                fig_box.add_trace(go.Box(y=self.df[col], name=col))\n",
    "            fig_box.update_layout(title=\"Box Plots Comparison\")\n",
    "            figures.append((\"Box Plots Comparison\", fig_box))\n",
    "        \n",
    "        # 4. Bar plots for categorical columns\n",
    "        for col in categorical_cols[:3]:  # Limit to first 3 columns\n",
    "            value_counts = self.df[col].value_counts().head(10)\n",
    "            fig_bar = px.bar(\n",
    "                x=value_counts.index, \n",
    "                y=value_counts.values,\n",
    "                title=f\"Top 10 Values in {col}\",\n",
    "                labels={'x': col, 'y': 'Count'}\n",
    "            )\n",
    "            figures.append((f\"Top Values in {col}\", fig_bar))\n",
    "        \n",
    "        # 5. Scatter plot matrix (if enough numeric columns)\n",
    "        if len(numeric_cols) >= 2:\n",
    "            sample_size = min(1000, len(self.df))  # Sample for performance\n",
    "            df_sample = self.df.sample(n=sample_size) if len(self.df) > sample_size else self.df\n",
    "            fig_scatter = px.scatter_matrix(\n",
    "                df_sample[numeric_cols[:4]], \n",
    "                title=\"Scatter Plot Matrix\"\n",
    "            )\n",
    "            figures.append((\"Scatter Plot Matrix\", fig_scatter))\n",
    "        \n",
    "        return figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ai_insights(self, user_prompt: str = None) -> str:\n",
    "        \"\"\"Get AI-powered insights from OpenAI\"\"\"\n",
    "        if not self.analysis_results:\n",
    "            return \"No analysis results available. Please perform EDA first.\"\n",
    "        \n",
    "        # Prepare data summary for AI\n",
    "        data_summary = json.dumps(self.analysis_results, indent=2, default=str)\n",
    "        \n",
    "        default_prompt = \"\"\"\n",
    "        As a data analyst, provide comprehensive insights about this dataset. \n",
    "        Focus on:\n",
    "        1. Key patterns and trends\n",
    "        2. Notable correlations\n",
    "        3. Data quality issues\n",
    "        4. Anomalies or outliers\n",
    "        5. Business recommendations\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt = user_prompt if user_prompt else default_prompt\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\", \n",
    "                        \"content\": \"You are an expert data analyst. Analyze the provided dataset summary and provide actionable insights.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\", \n",
    "                        \"content\": f\"{prompt}\\n\\nDataset Summary:\\n{data_summary}\"\n",
    "                    }\n",
    "                ],\n",
    "                max_tokens=1500,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            return f\"Error generating AI insights: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(self, user_prompt: str = None) -> str:\n",
    "        \"\"\"Generate a comprehensive report\"\"\"\n",
    "        if self.df is None:\n",
    "            return \"No data loaded. Please upload a dataset first.\"\n",
    "        \n",
    "        # Perform EDA\n",
    "        self.perform_eda(user_prompt)\n",
    "        \n",
    "        # Get AI insights\n",
    "        insights = self.get_ai_insights(user_prompt)\n",
    "        \n",
    "        # Create report structure\n",
    "        report = f\"\"\"\n",
    "        # Auto-Generated Data Analysis Report\n",
    "        \n",
    "        ## Dataset Overview\n",
    "        - **Shape**: {self.analysis_results['data_summary']['shape']}\n",
    "        - **Columns**: {len(self.analysis_results['data_summary']['columns'])}\n",
    "        - **Missing Values**: {sum(self.analysis_results['data_summary']['missing_values'].values())}\n",
    "        - **Duplicate Rows**: {self.analysis_results['data_summary']['duplicate_rows']}\n",
    "        \n",
    "        ## AI-Powered Insights\n",
    "        {insights}\n",
    "        \n",
    "        ## Technical Summary\n",
    "        - **Numeric Columns**: {len(self.analysis_results['data_summary']['numeric_columns'])}\n",
    "        - **Categorical Columns**: {len(self.analysis_results['data_summary']['categorical_columns'])}\n",
    "        - **Memory Usage**: {self.analysis_results['data_summary']['memory_usage'] / 1024 / 1024:.2f} MB\n",
    "        \"\"\"\n",
    "        \n",
    "        return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 22:37:39.434 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/anaconda3/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    st.title(\"📊 Auto Report Generator\")\n",
    "    st.markdown(\"Upload your dataset and get AI-powered insights with automated EDA!\")\n",
    "    \n",
    "    # Sidebar for configuration\n",
    "    st.sidebar.header(\"Configuration\")\n",
    "    \n",
    "    # OpenAI API Key input\n",
    "    api_key = st.sidebar.text_input(\"Enter OpenAI API Key\", type=\"password\")\n",
    "    \n",
    "    if not api_key:\n",
    "        st.warning(\"Please enter your OpenAI API key in the sidebar to proceed.\")\n",
    "        return\n",
    "    \n",
    "    # Initialize the generator\n",
    "    generator = AutoReportGenerator(api_key)\n",
    "    \n",
    "    # File upload\n",
    "    st.sidebar.header(\"Data Upload\")\n",
    "    uploaded_file = st.sidebar.file_uploader(\n",
    "        \"Choose a file\", \n",
    "        type=['csv', 'xlsx', 'xls', 'json']\n",
    "    )\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        if generator.load_data(uploaded_file):\n",
    "            # Display basic info about the dataset\n",
    "            st.subheader(\"Dataset Preview\")\n",
    "            st.dataframe(generator.df.head())\n",
    "            \n",
    "            col1, col2, col3, col4 = st.columns(4)\n",
    "            with col1:\n",
    "                st.metric(\"Rows\", generator.df.shape[0])\n",
    "            with col2:\n",
    "                st.metric(\"Columns\", generator.df.shape[1])\n",
    "            with col3:\n",
    "                st.metric(\"Missing Values\", generator.df.isnull().sum().sum())\n",
    "            with col4:\n",
    "                st.metric(\"Memory Usage\", f\"{generator.df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")\n",
    "            \n",
    "            # Custom prompt input\n",
    "            st.subheader(\"Custom Analysis Prompt\")\n",
    "            user_prompt = st.text_area(\n",
    "                \"Enter your specific analysis requirements (optional):\",\n",
    "                placeholder=\"e.g., Focus on sales trends, identify customer segments, analyze seasonal patterns...\"\n",
    "            )\n",
    "            \n",
    "            # Generate report button\n",
    "            if st.button(\"🚀 Generate Auto Report\", type=\"primary\"):\n",
    "                with st.spinner(\"Performing EDA and generating insights...\"):\n",
    "                    # Generate comprehensive report\n",
    "                    report = generator.generate_report(user_prompt if user_prompt else None)\n",
    "                    \n",
    "                    # Display report\n",
    "                    st.markdown(report)\n",
    "                    \n",
    "                    # Generate and display visualizations\n",
    "                    st.subheader(\"📈 Visualizations\")\n",
    "                    figures = generator.generate_visualizations()\n",
    "                    \n",
    "                    for title, fig in figures:\n",
    "                        st.plotly_chart(fig, use_container_width=True)\n",
    "                    \n",
    "                    # Display raw analysis results\n",
    "                    with st.expander(\"🔍 Detailed Analysis Results\"):\n",
    "                        st.json(generator.analysis_results)\n",
    "    \n",
    "    # Chatbot interface\n",
    "    st.subheader(\"💬 Ask Questions About Your Data\")\n",
    "    \n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state.messages = []\n",
    "    \n",
    "    # Display chat messages\n",
    "    for message in st.session_state.messages:\n",
    "        with st.chat_message(message[\"role\"]):\n",
    "            st.markdown(message[\"content\"])\n",
    "    \n",
    "    # Chat input\n",
    "    if prompt := st.chat_input(\"Ask me anything about your dataset...\"):\n",
    "        if uploaded_file is None:\n",
    "            st.error(\"Please upload a dataset first!\")\n",
    "        else:\n",
    "            # Add user message to chat history\n",
    "            st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "            \n",
    "            # Display user message\n",
    "            with st.chat_message(\"user\"):\n",
    "                st.markdown(prompt)\n",
    "            \n",
    "            # Generate assistant response\n",
    "            with st.chat_message(\"assistant\"):\n",
    "                with st.spinner(\"Analyzing...\"):\n",
    "                    response = generator.get_ai_insights(prompt)\n",
    "                    st.markdown(response)\n",
    "            \n",
    "            # Add assistant response to chat history\n",
    "            st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
